<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The Basic Knowledge of Prompt Engineering | Shoutao'Log</title>
<meta name=keywords content="Prompt Engineering,Large Language Models"><meta name=description content="Some basic knowledge you must know during the process of Prompt Engineering learning💻"><meta name=author content="Shoutao Sun"><link rel=canonical href=https://ShoutaoSun.github.io/posts/prompt_engineering/><link crossorigin=anonymous href=/assets/css/stylesheet.77bb08daa0ae5ca36f886d66f7dc412f4cc50d9ef4d629992cfa13bf980b83c4.css integrity="sha256-d7sI2qCuXKNviG1m99xBL0zFDZ701imZLPoTv5gLg8Q=" rel="preload stylesheet" as=style><link rel=icon href=https://ShoutaoSun.github.io/sea.ico><link rel=icon type=image/png sizes=16x16 href=https://ShoutaoSun.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://ShoutaoSun.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://ShoutaoSun.github.io/sea.ico><link rel=mask-icon href=https://ShoutaoSun.github.io/sea.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ShoutaoSun.github.io/posts/prompt_engineering/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ShoutaoSun.github.io/posts/prompt_engineering/"><meta property="og:site_name" content="Shoutao'Log"><meta property="og:title" content="The Basic Knowledge of Prompt Engineering"><meta property="og:description" content="Some basic knowledge you must know during the process of Prompt Engineering learning💻"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-01T08:58:19+08:00"><meta property="article:modified_time" content="2024-12-01T08:58:19+08:00"><meta property="article:tag" content="Prompt Engineering"><meta property="article:tag" content="Large Language Models"><meta name=twitter:card content="summary"><meta name=twitter:title content="The Basic Knowledge of Prompt Engineering"><meta name=twitter:description content="Some basic knowledge you must know during the process of Prompt Engineering learning💻"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"","item":"https://ShoutaoSun.github.io/posts/"},{"@type":"ListItem","position":2,"name":"The Basic Knowledge of Prompt Engineering","item":"https://ShoutaoSun.github.io/posts/prompt_engineering/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The Basic Knowledge of Prompt Engineering","name":"The Basic Knowledge of Prompt Engineering","description":"Some basic knowledge you must know during the process of Prompt Engineering learning💻","keywords":["Prompt Engineering","Large Language Models"],"articleBody":"前言 提示工程 (Prompt Engineering) 是一门较新的学科，关注提示词开发和优化，帮助用户将大语言模型 (Large Language Model, LLM) 用于各场景和研究领域。掌握了提示工程相关技能将有助于用户更好地了解大型语言模型的能力和局限性。\n研究人员可利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。开发人员可通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。\n提示工程不仅仅是关于设计和研发提示词。它包含了与大语言模型交互和研发的各种技能和技术。提示工程在实现和大语言模型交互、对接，以及理解大语言模型能力方面都起着重要作用。用户可以通过提示工程来提高大语言模型的安全性，也可以赋能大语言模型，比如借助专业领域知识和外部工具来增强大语言模型能力。\n提示工程简介 本部分介绍了提示词相关的基础知识，帮助了解如何通过提示词和 LLM 进行交互并提供指导建议。\n模型设置 使用提示词时，我们通常会使用 API 或直接与 LLM 进行交互。我们可以通过配置一些参数以获得不同的提示结果。调整这些设置对于提高响应的可靠性非常重要，需要进行一些实验才能找出适合个人用例的正确设置。以下是使用不同 LLM 提供程序时会遇到的常见设置。\nTemperature 用于控制模型返回结果的确定性。temperature的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，模型就会返回越确定的一个结果。如果调高该参数值，LLM 会返回更随机的结果。调小temperature实际上是在增加其他可能的 token 的权重。\n实际应用：\n质量保障 (QA)：设置更低的temperature，促使模型基于事实返回更真实和简洁的结果 诗歌生成：适度地调高temperature参数值可能会更好 Top_p 用于控制模型返回结果的确定性。与temperature类似，如果需要准确和事实的答案，就把参数值调低；如果需要更多样化的响应，就把参数值调高。\n一般建议是改变temperature和top_p中的一个参数即可，不需要两个都调整。\nMax Length 用于控制大模型生成的 token 数。指定Max Length有助于防止大模型生成冗长或不相关的响应，同时控制成本。\nStop Sequences stop sequence是一个字符串，可以阻止模型生成 token，指定stop sequence是控制 LLM 响应长度和结构的另一种方法。eg: 通过添加“11”作为stop sequence来告诉模型生成不超过 10 个项的列表。\nFrequency Penalty frequency penalty是对下一个生成的 token 进行惩罚，这个惩罚和 token 在响应和提示中已出现的次数成比例，frequency penalty越高，某个词再次出现的可能性就越小，通过设置frequency penalty可以给重复数量多的 token 设置更高的惩罚以减少响应中单词的重复。\nPresence Penalty presence penalty也是对重复的 token 施加惩罚，但与frequency penalty不同，presence penalty对于所有重复的 token 都是相同的（出现 2 次的 token 和出现 10 次的 token 会受到相同的惩罚）。此设置可以防止模型在响应中过于频繁地生成重复的词。\n与temperature和top_p一样，一般建议是改变frequency penalty和presence penalty其中一个参数就行，无须同时调整两个。\n基本概念 设计有效的提示词以指导模型执行期望任务的方法被称为提示工程。\n提示词格式 标准提示词应遵循以下格式。\n\u003c问题\u003e? 或\n\u003c指令\u003e? 提示词要素 提示词可包含以下任意要素。\n指令：想要模型执行的特定任务或指令； 上下文：包含外部信息或额外的上下文信息，引导语言模型更好地响应； 输入数据：用户输入的内容或问题； 输出指示：指定输出的类型或格式。 示例如下：\n请将文本分为肯定、否定或中性。 # 指令 文本：我觉得食物还可以。 # 输入数据 情绪： # 输出指示 补充说明，提示词所需的格式取决于用户想要语言模型完成的任务类型，并非所有以上要素都是必须的。\n设计提示的通用技巧 指令：使用命令指示模型执行各种简单任务，例如“写入”、“分类”、“总结”等，从而为各种简单任务设计有效的提示；需要以不同的关键词、上下文和数据对不同的指令进行大量实验，寻找最适合特定用例和任务的指令 具体性：具有良好格式和描述性的提示词，同时注意提示的长度，不要包含太多不必要的细节 避免不准确：具体、简洁并切中要点，例如：“使用 2-3 句话向高中学生解释提示工程的概念” 做什么还是不做什么：避免说不要做什么，而应该说要做什么 更多的参考案例详见 Best practices for prompt engineering with the OpenAI API\n提示技术 零样本提示 直接提示模型给出一个回答，而没有提供任何关于你希望它完成的任务的示例。案例如下所示。\n提示：\n将文本分类为中性、负面或正面。 文本：我认为这次假期还可以。 情感： 输出：\n中性 指令调整已被证明可以改善零样本学习 Wei et al (2022) 。指令调整本质上是在通过指令描述的数据集上微调模型的概念。此外，RLHF 已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。\n少样本提示 虽然 LLM 展示了惊人的零样本能力，但在使用零样本设置时，它们在更复杂的任务上仍表现不佳。少样本提示可以作为一种技术，以启用上下文学习。少样本提示的格式示例如下。\n\u003c问题\u003e? \u003c答案\u003e \u003c问题\u003e? \u003c答案\u003e \u003c问题\u003e? \u003c答案\u003e \u003c问题\u003e? 根据 Min et al (2022) 的研究结果，以下是在进行少样本学习时关于示例的一些额外提示。\n标签空间和示例指定的输入文本的分布都很重要（无论标签对单个输入是否正确） 使用的格式也对性能起着关键作用，即使只是使用随机标签，这也比没有标签好得多 其他结果表明，从真实标签分布（而不是均匀分布）中选择随机标签也有帮助 首先尝试一个随机标签的例子（意味着将标签 Negative 和 Positive 随机分配给输入。\n提示：\n这太棒了！// Negative 这太糟糕了！// Positive 哇，那部电影太棒了！// Positive 多么可怕的节目！// 输出：\nNegative 即使标签已经随机化，仍然得到了正确的答案，除此之外，案例还保留了格式，这也有助于生成正确的答案。实际上，通过进一步的实验，新的 GPT 模型对随机格式也变得更加稳健，例如：\n提示：\nPositive This is awesome! This is bad! Negative Wow that movie was rad! Positive What a horrible show! -- 输出：\nNegative 少样本提示的限制 标准的少样本提示对许多任务都有效，但仍然不是一种完美的技术，特别是在处理更复杂的推理任务时。总的来说，提供示例对解决某些任务很有用。当零样本提示和少样本提示不足时，这可能意味着模型学到的东西不足以在任务上表现良好。此时建议考虑微调模型或尝试更高级的提示技术。\n链式思考（Chain of Thought, CoT）提示 在 Wei et al, 2022 中引入的链式思考（CoT）提示通过中间推理步骤实现了复杂的推理能力。可以将其与少样本提示相结合，获得更好的结果，从而能够解决需要进行推理的更复杂的任务。\n提示：\n这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。 A：将所有奇数相加（9、15、1）得到25。答案为False。 这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。 A： 输出：\n将所有奇数相加（15、5、13、7、1）得到41。答案为False。 补充说明，作者生成这是足够大的语言模型才会出现的能力。\n零样本 CoT 提示 最近提出的一个新想法是零样本 CoT Kojima et al, 2022，它基本涉及将“让我们逐步思考”添加到原始提示中。\n自动思维链（Auto-CoT） 当使用思维链提示时，这个过程需要手工制作有效且多样化的例子，这种手动工作可能会导致次优解决方案。Zhang et al, 2022 提出了一种消除人工的方法，即利用 LLMs“让我们一步一步地思考”提示来生成一个接一个的推理链。这种自动过程仍然可能在生成的链中出现错误。为了减轻错误的影响，示例的多样性很重要。这项工作提出了 Auto-CoT，它对具有多样性的问题进行采样，并生成推理链来构建演示。\nAuto-CoT 主要由两个阶段组成。\nPeriod 1. 问题聚类，将给定问题划分为几个聚类 Period 2. 示例抽样，从每个数组中选择一个具有代表性的问题，并使用带有简单启发式的零样本 CoT 生成其推理链 简单的启发式方法可以是问题的长度（例如，60 个 tokens）和理由的步骤数（例如，5 个推理步骤）。这鼓励模型使用简单而准确的示例。\n该过程如下图所示，代码见 Auto-CoT\n自我一致性 通过少样本 CoT 采样多个不同的推理路径，并使用生成结果选择最一致的答案，这有助于提高 CoT 提示在涉及计算和常识推理的任务中的性能。\n例如以下计算推理示例。\n提示：\n当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？ 输出：\n35 输出是错误的，可通过自我一致性来改进这个问题，将使用 Wang et al, 2022 的少样本示例，如下图所示。\n输出：\n当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70-3 = 67岁。答案是67。 # Output 1 当叙述者6岁时，他的妹妹是他年龄的一半，也就是3岁。现在叙述者70岁了，他的妹妹应该是70-3 = 67岁。答案是67。 # Output 2 当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70/2 = 35岁。答案是35。 # Output 3 计算最终答案涉及几个步骤（详见论文），但为了简单起见，可以看到已经出现了大多数答案，因此这基本上将成为最终答案。\n","wordCount":"3655","inLanguage":"en","datePublished":"2024-12-01T08:58:19+08:00","dateModified":"2024-12-01T08:58:19+08:00","author":[{"@type":"Person","name":"Shoutao Sun"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://ShoutaoSun.github.io/posts/prompt_engineering/"},"publisher":{"@type":"Organization","name":"Shoutao'Log","logo":{"@type":"ImageObject","url":"https://ShoutaoSun.github.io/sea.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ShoutaoSun.github.io/ accesskey=h title="Shoutao'Log (Alt + H)">Shoutao'Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ShoutaoSun.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://ShoutaoSun.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://ShoutaoSun.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://ShoutaoSun.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/ikatyang/emoji-cheat-sheet/blob/master/README.md title="Emoji Search"><span>Emoji Search</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://ShoutaoSun.github.io/friends/ title=Friends><span>Friends</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ShoutaoSun.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ShoutaoSun.github.io/posts/></a></div><h1 class="post-title entry-hint-parent">The Basic Knowledge of Prompt Engineering</h1><div class=post-meta><span title='2024-12-01 08:58:19 +0800 CST'>December 1, 2024</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;3655 words&nbsp;·&nbsp;Shoutao Sun</div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css integrity=sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js integrity=sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#前言>前言</a></li><li><a href=#提示工程简介>提示工程简介</a><ul><li><a href=#模型设置>模型设置</a></li><li><a href=#基本概念>基本概念</a></li><li><a href=#提示词要素>提示词要素</a></li><li><a href=#设计提示的通用技巧>设计提示的通用技巧</a></li></ul></li><li><a href=#提示技术>提示技术</a><ul><li><a href=#零样本提示>零样本提示</a></li><li><a href=#少样本提示>少样本提示</a></li><li><a href=#链式思考chain-of-thought-cot提示>链式思考（Chain of Thought, CoT）提示</a></li><li><a href=#零样本-cot-提示>零样本 CoT 提示</a></li><li><a href=#自动思维链auto-cot>自动思维链（Auto-CoT）</a></li><li><a href=#自我一致性>自我一致性</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=前言>前言<a hidden class=anchor aria-hidden=true href=#前言>#</a></h2><p><strong>提示工程</strong> (Prompt Engineering) 是一门较新的学科，关注提示词开发和优化，帮助用户将<strong>大语言模型</strong> (Large Language Model, LLM) 用于各场景和研究领域。掌握了提示工程相关技能将有助于用户更好地了解大型语言模型的能力和局限性。</p><p>研究人员可利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。开发人员可通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。</p><p>提示工程不仅仅是关于设计和研发提示词。它包含了与大语言模型交互和研发的各种技能和技术。提示工程在实现和大语言模型交互、对接，以及理解大语言模型能力方面都起着重要作用。用户可以通过提示工程来提高大语言模型的安全性，也可以赋能大语言模型，比如借助专业领域知识和外部工具来增强大语言模型能力。</p><h2 id=提示工程简介>提示工程简介<a hidden class=anchor aria-hidden=true href=#提示工程简介>#</a></h2><p>本部分介绍了提示词相关的基础知识，帮助了解如何通过提示词和 LLM 进行交互并提供指导建议。</p><h3 id=模型设置>模型设置<a hidden class=anchor aria-hidden=true href=#模型设置>#</a></h3><p>使用提示词时，我们通常会使用 API 或直接与 LLM 进行交互。我们可以通过配置一些参数以获得不同的提示结果。调整这些设置对于提高响应的可靠性非常重要，需要进行一些实验才能找出适合个人用例的正确设置。以下是使用不同 LLM 提供程序时会遇到的常见设置。</p><h4 id=temperature>Temperature<a hidden class=anchor aria-hidden=true href=#temperature>#</a></h4><p>用于<strong>控制模型返回结果的确定性</strong>。<code>temperature</code>的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，模型就会返回越确定的一个结果。如果调高该参数值，LLM 会返回更随机的结果。调小<code>temperature</code>实际上是在增加其他可能的 token 的权重。</p><p>实际应用：</p><ul><li>质量保障 (QA)：设置更低的<code>temperature</code>，促使模型基于事实返回更真实和简洁的结果</li><li>诗歌生成：适度地调高<code>temperature</code>参数值可能会更好</li></ul><h4 id=top_p>Top_p<a hidden class=anchor aria-hidden=true href=#top_p>#</a></h4><p>用于<strong>控制模型返回结果的确定性</strong>。与<code>temperature</code>类似，如果需要准确和事实的答案，就把参数值调低；如果需要更多样化的响应，就把参数值调高。</p><p>一般建议是改变<code>temperature</code>和<code>top_p</code>中的一个参数即可，不需要两个都调整。</p><h4 id=max-length>Max Length<a hidden class=anchor aria-hidden=true href=#max-length>#</a></h4><p>用于<strong>控制大模型生成的 token 数</strong>。指定<code>Max Length</code>有助于防止大模型生成冗长或不相关的响应，同时控制成本。</p><h4 id=stop-sequences>Stop Sequences<a hidden class=anchor aria-hidden=true href=#stop-sequences>#</a></h4><p><code>stop sequence</code>是一个字符串，可以阻止模型生成 token，指定<code>stop sequence</code>是<strong>控制 LLM 响应长度和结构</strong>的另一种方法。eg: 通过添加“11”作为<code>stop sequence</code>来告诉模型生成不超过 10 个项的列表。</p><h4 id=frequency-penalty>Frequency Penalty<a hidden class=anchor aria-hidden=true href=#frequency-penalty>#</a></h4><p><code>frequency penalty</code>是对下一个生成的 token 进行惩罚，这个惩罚和 token 在响应和提示中已出现的次数成比例，<code>frequency penalty</code>越高，某个词再次出现的可能性就越小，通过设置<code>frequency penalty</code>可以<strong>给重复数量多的</strong> <strong>token 设置更高的惩罚以减少响应中单词的重复</strong>。</p><h4 id=presence-penalty>Presence Penalty<a hidden class=anchor aria-hidden=true href=#presence-penalty>#</a></h4><p><code>presence penalty</code>也是对重复的 token 施加惩罚，但与<code>frequency penalty</code>不同，<code>presence penalty</code>对于所有重复的 token 都是相同的（出现 2 次的 token 和出现 10 次的 token 会受到相同的惩罚）。此设置可以<strong>防止模型在响应中过于频繁地生成重复的词</strong>。</p><p>与<code>temperature</code>和<code>top_p</code>一样，一般建议是改变<code>frequency penalty</code>和<code>presence penalty</code>其中一个参数就行，无须同时调整两个。</p><h3 id=基本概念>基本概念<a hidden class=anchor aria-hidden=true href=#基本概念>#</a></h3><p>设计有效的提示词以指导模型执行期望任务的方法被称为<strong>提示工程</strong>。</p><h4 id=提示词格式>提示词格式<a hidden class=anchor aria-hidden=true href=#提示词格式>#</a></h4><p>标准提示词应遵循以下格式。</p><pre tabindex=0><code>&lt;问题&gt;?
</code></pre><p>或</p><pre tabindex=0><code>&lt;指令&gt;?
</code></pre><h3 id=提示词要素>提示词要素<a hidden class=anchor aria-hidden=true href=#提示词要素>#</a></h3><p>提示词可包含以下任意要素。</p><ul><li><strong>指令</strong>：想要模型执行的特定任务或指令；</li><li><strong>上下文</strong>：包含外部信息或额外的上下文信息，引导语言模型更好地响应；</li><li><strong>输入数据</strong>：用户输入的内容或问题；</li><li><strong>输出指示</strong>：指定输出的类型或格式。</li></ul><p>示例如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>请将文本分为肯定、否定或中性。  # 指令
</span></span><span style=display:flex><span>文本：我觉得食物还可以。  # 输入数据
</span></span><span style=display:flex><span>情绪：  # 输出指示
</span></span></code></pre></div><p>补充说明，提示词所需的格式取决于用户想要语言模型完成的任务类型，并非所有以上要素都是必须的。</p><h3 id=设计提示的通用技巧>设计提示的通用技巧<a hidden class=anchor aria-hidden=true href=#设计提示的通用技巧>#</a></h3><ul><li><strong>指令</strong>：使用命令指示模型执行各种简单任务，例如“写入”、“分类”、“总结”等，从而为各种简单任务设计有效的提示；需要以不同的关键词、上下文和数据对不同的指令进行大量实验，寻找最适合特定用例和任务的指令</li><li><strong>具体性</strong>：具有良好格式和描述性的提示词，同时注意提示的长度，不要包含太多不必要的细节</li><li><strong>避免不准确</strong>：具体、简洁并切中要点，例如：“使用 2-3 句话向高中学生解释提示工程的概念”</li><li><strong>做什么还是不做什么</strong>：避免说不要做什么，而应该说要做什么</li></ul><p>更多的参考案例详见 <a href=https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api><strong>Best practices for prompt engineering with the OpenAI API</strong></a></p><h2 id=提示技术>提示技术<a hidden class=anchor aria-hidden=true href=#提示技术>#</a></h2><h3 id=零样本提示>零样本提示<a hidden class=anchor aria-hidden=true href=#零样本提示>#</a></h3><p>直接提示模型给出一个回答，而没有提供任何关于你希望它完成的任务的示例。案例如下所示。</p><p><em>提示：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>将文本分类为中性、负面或正面。
</span></span><span style=display:flex><span>文本：我认为这次假期还可以。
</span></span><span style=display:flex><span>情感：
</span></span></code></pre></div><p><em>输出：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>中性
</span></span></code></pre></div><p>指令调整已被证明可以改善零样本学习 <a href=https://arxiv.org/pdf/2109.01652>Wei et al (2022) </a>。<strong>指令调整本质上是在通过指令描述的数据集上微调模型的概念</strong>。此外，<a href=https://arxiv.org/abs/1706.03741>RLHF</a> 已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。</p><h3 id=少样本提示>少样本提示<a hidden class=anchor aria-hidden=true href=#少样本提示>#</a></h3><p>虽然 LLM 展示了惊人的零样本能力，但在使用零样本设置时，它们在更复杂的任务上仍表现不佳。少样本提示可以作为一种技术，以启用上下文学习。少样本提示的格式示例如下。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>&lt;问题&gt;?
</span></span><span style=display:flex><span>&lt;答案&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;问题&gt;?
</span></span><span style=display:flex><span>&lt;答案&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;问题&gt;?
</span></span><span style=display:flex><span>&lt;答案&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;问题&gt;?
</span></span></code></pre></div><p>根据 <a href=https://arxiv.org/abs/2202.12837>Min et al (2022)</a> 的研究结果，以下是在进行少样本学习时关于示例的一些额外提示。</p><ul><li><strong>标签空间和示例指定的输入文本的分布</strong>都很重要（无论标签对单个输入是否正确）</li><li>使用的<strong>格式</strong>也对性能起着关键作用，即使只是使用随机标签，这也比没有标签好得多</li><li>其他结果表明，从<strong>真实标签分布</strong>（而不是均匀分布）<strong>中选择随机标签</strong>也有帮助</li></ul><p>首先尝试一个随机标签的例子（意味着将标签 Negative 和 Positive 随机分配给输入。</p><p><em>提示：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>这太棒了！// Negative
</span></span><span style=display:flex><span>这太糟糕了！// Positive
</span></span><span style=display:flex><span>哇，那部电影太棒了！// Positive
</span></span><span style=display:flex><span>多么可怕的节目！//
</span></span></code></pre></div><p><em>输出：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>Negative
</span></span></code></pre></div><p>即使标签已经随机化，仍然得到了正确的答案，除此之外，案例还保留了格式，这也有助于生成正确的答案。实际上，通过进一步的实验，新的 GPT 模型对随机格式也变得更加稳健，例如：</p><p><em>提示：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>Positive This is awesome! 
</span></span><span style=display:flex><span>This is bad! Negative
</span></span><span style=display:flex><span>Wow that movie was rad!
</span></span><span style=display:flex><span>Positive
</span></span><span style=display:flex><span>What a horrible show! --
</span></span></code></pre></div><p><em>输出：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>Negative
</span></span></code></pre></div><h4 id=少样本提示的限制>少样本提示的限制<a hidden class=anchor aria-hidden=true href=#少样本提示的限制>#</a></h4><p>标准的少样本提示对许多任务都有效，但仍然不是一种完美的技术，特别是在处理更复杂的推理任务时。总的来说，提供示例对解决某些任务很有用。当零样本提示和少样本提示不足时，这可能意味着模型学到的东西不足以在任务上表现良好。此时建议考虑微调模型或尝试更高级的提示技术。</p><h3 id=链式思考chain-of-thought-cot提示>链式思考（Chain of Thought, CoT）提示<a hidden class=anchor aria-hidden=true href=#链式思考chain-of-thought-cot提示>#</a></h3><p>在 <a href=https://arxiv.org/abs/2201.11903>Wei et al, 2022</a> 中引入的链式思考（CoT）提示通过中间推理步骤实现了复杂的推理能力。可以将其与少样本提示相结合，获得更好的结果，从而能够解决需要进行推理的更复杂的任务。</p><p><img alt=Fig.1. loading=lazy src=/images/1733056949988-e5c33b27-8b25-428b-93d8-3a3bbbae0d77.png#center></p><p><em>提示：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。
</span></span><span style=display:flex><span>A：将所有奇数相加（9、15、1）得到25。答案为False。
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。
</span></span><span style=display:flex><span>A：
</span></span></code></pre></div><p><em>输出：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>将所有奇数相加（15、5、13、7、1）得到41。答案为False。
</span></span></code></pre></div><p>补充说明，作者生成这是足够大的语言模型才会出现的能力。</p><h3 id=零样本-cot-提示>零样本 CoT 提示<a hidden class=anchor aria-hidden=true href=#零样本-cot-提示>#</a></h3><p><img alt=Fig.2. loading=lazy src=/images/1733057546274-9843f543-4d59-478d-8cd3-6f1aab7d5b0d.png#center></p><p>最近提出的一个新想法是零样本 CoT <a href=https://arxiv.org/abs/2205.11916>Kojima et al, 2022</a>，它基本涉及将“让我们逐步思考”添加到原始提示中。</p><h3 id=自动思维链auto-cot>自动思维链（Auto-CoT）<a hidden class=anchor aria-hidden=true href=#自动思维链auto-cot>#</a></h3><p>当使用思维链提示时，这个过程需要手工制作有效且多样化的例子，这种手动工作可能会导致次优解决方案。<a href=https://arxiv.org/abs/2210.03493>Zhang et al, 2022</a> 提出了一种消除人工的方法，即利用 LLMs“让我们一步一步地思考”提示来生成一个接一个的推理链。这种自动过程仍然可能在生成的链中出现错误。为了减轻错误的影响，示例的多样性很重要。这项工作提出了 Auto-CoT，它对具有多样性的问题进行采样，并生成推理链来构建演示。</p><p>Auto-CoT 主要由两个阶段组成。</p><ul><li>Period 1. <strong>问题聚类</strong>，将给定问题划分为几个聚类</li><li>Period 2. <strong>示例抽样</strong>，从每个数组中选择一个具有代表性的问题，并使用带有简单启发式的零样本 CoT 生成其推理链</li></ul><p>简单的启发式方法可以是问题的长度（例如，60 个 tokens）和理由的步骤数（例如，5 个推理步骤）。这鼓励模型使用简单而准确的示例。</p><p>该过程如下图所示，代码见 <a href=https://github.com/amazon-science/auto-cot>Auto-CoT</a></p><p><img alt=Fig.3. loading=lazy src=/images/1733058467147-1ccd0398-28d5-4d4b-895b-6e9add293ec7.png#center></p><h3 id=自我一致性>自我一致性<a hidden class=anchor aria-hidden=true href=#自我一致性>#</a></h3><p>通过少样本 CoT 采样多个不同的推理路径，并使用生成结果选择最一致的答案，这有助于提高 CoT 提示在涉及计算和常识推理的任务中的性能。</p><p>例如以下计算推理示例。</p><p><em>提示：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？
</span></span></code></pre></div><p><em>输出：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>35
</span></span></code></pre></div><p>输出是错误的，可通过自我一致性来改进这个问题，将使用 <a href=https://arxiv.org/pdf/2203.11171>Wang et al, 2022</a> 的少样本示例，如下图所示。</p><p><img alt=Fig.4. loading=lazy src=/images/1733058838266-3231bb7b-5c4f-44e8-8177-af85b55120d5.png#center></p><p><em>输出：</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70-3 = 67岁。答案是67。  # Output 1
</span></span><span style=display:flex><span>当叙述者6岁时，他的妹妹是他年龄的一半，也就是3岁。现在叙述者70岁了，他的妹妹应该是70-3 = 67岁。答案是67。  # Output 2
</span></span><span style=display:flex><span>当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70/2 = 35岁。答案是35。  # Output 3
</span></span></code></pre></div><p>计算最终答案涉及几个步骤（详见论文），但为了简单起见，可以看到已经出现了大多数答案，因此这基本上将成为最终答案。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://ShoutaoSun.github.io/tags/prompt-engineering/>Prompt Engineering</a></li><li><a href=https://ShoutaoSun.github.io/tags/large-language-models/>Large Language Models</a></li></ul><nav class=paginav><a class=prev href=https://ShoutaoSun.github.io/posts/tools/><span class=title>« Prev</span><br><span>Practical Tools of AI</span>
</a><a class=next href=https://ShoutaoSun.github.io/posts/adv_llm_11_17/><span class=title>Next »</span><br><span>Adversarial attacks and defenses for large language models (LLMs): methods, frameworks & challenges</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://ShoutaoSun.github.io/>Shoutao'Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>